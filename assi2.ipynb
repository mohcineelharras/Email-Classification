{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25066, 13) (10745, 12)\n",
      "(25066, 13)\n",
      "(25066, 13) (10745, 12)\n",
      "Done\n",
      "(25066,) (10745,)\n",
      "(25066,) (10745,)\n",
      "(25066,) (10745,)\n",
      "(25066, 6) (10745, 6)\n",
      "(25066, 6) (10745, 6)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "## Read csvs\n",
    "train_df = pd.read_csv('train.csv', index_col=0)\n",
    "test_df = pd.read_csv('test.csv', index_col=0)\n",
    "\n",
    "\n",
    "Q1 = train_df.quantile(0.25)\n",
    "Q3 = train_df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "train_df = train_df[~((train_df < (Q1 - 1.5 * IQR)) |(train_df > (Q3 + 5 * IQR))).any(axis=1)].reset_index()\n",
    "#train_df.shape\n",
    "\n",
    "#Drop Duplicates\n",
    "\n",
    "#Not sure is a good idea\n",
    "#train_df.drop_duplicates(keep=False,inplace=True)\n",
    "#test_df.drop_duplicates(keep=False,inplace=True)\n",
    "\n",
    "\n",
    "print(train_df.shape,test_df.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#FILTER OUTLIERS\n",
    "#urls<350    PLUS STRICT 150\n",
    "#images<85   PLUS STRICT 30\n",
    "#chars_in_subject<300  PLUS STRICT 120\n",
    "#chars_in_body<20000000  PLUS STRICT 130000\n",
    "\n",
    "#train_df_urls = train_df[train_df.urls <= 350]\n",
    "#train_df_images = train_df_urls[train_df_urls.images <= 85]\n",
    "#train_df_subject = train_df_images[train_df_images.chars_in_subject <= 300]\n",
    "#train_df_body = train_df_subject[train_df_subject.chars_in_body <= 1000000]\n",
    "#train_df=train_df_body.reset_index()\n",
    "#print(train_df.shape)\n",
    "\n",
    "#train_df.urls.loc[train_df.urls > 350]=350\n",
    "#train_df.images.loc[train_df.images > 85]=85\n",
    "#train_df.chars_in_subject.loc[train_df.chars_in_subject > 300]=300\n",
    "#train_df.chars_in_body.loc[train_df.chars_in_body > 1000000]=1000000\n",
    "\n",
    "print(train_df.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Handle missing values\n",
    "train_df.fillna('NA', inplace=True)\n",
    "test_df.fillna('NA', inplace=True)\n",
    "\n",
    "print(train_df.shape,test_df.shape)\n",
    "\n",
    "##Reset Indexes\n",
    "train_df=train_df.reset_index()\n",
    "test_df=test_df.reset_index()\n",
    "\n",
    "## Filtering column Categorical\n",
    "mail_type_train = train_df['mail_type'].str.lower()\n",
    "tld_train = train_df['tld'].str.lower()\n",
    "org_train = train_df['org'].str.lower()\n",
    "\n",
    "mail_type_test = test_df['mail_type'].str.lower()\n",
    "tld_test = test_df['tld'].str.lower()\n",
    "org_test = test_df['org'].str.lower()\n",
    "\n",
    "train_y = train_df[['label']]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Fix TLD\n",
    "fix=tld_train.str.rsplit('.',n=1,expand=True)\n",
    "for b in range(fix.shape[0]):\n",
    "    if fix[1][b]==None:\n",
    "        fix[1][b]=fix[0][b]\n",
    "tld_train=fix[1].str.lower()\n",
    "\n",
    "\n",
    "fix=tld_test.str.rsplit('.',n=1,expand=True)\n",
    "for b in range(fix.shape[0]):\n",
    "    if fix[1][b]==None:\n",
    "        fix[1][b]=fix[0][b]\n",
    "tld_test=fix[1].str.lower()\n",
    "print(\"Done\")\n",
    "tld_train=tld_train.rename(\"tld\")\n",
    "tld_test=tld_test.rename(\"tld\")\n",
    "\n",
    "\n",
    "#Binary values\n",
    "num_cols_train=train_df[['salutations','designation']]\n",
    "\n",
    "num_cols_test=test_df[['salutations','designation']]\n",
    "\n",
    "#Numeric values\n",
    "num_cols_train_to_normalize=train_df[['images','urls','chars_in_subject','chars_in_body']]\n",
    "\n",
    "num_cols_test_to_normalize=test_df[['images','urls','chars_in_subject','chars_in_body']]\n",
    "\n",
    "\n",
    "##########'ccs','bcced'\n",
    "\n",
    "\n",
    "#Normalization\n",
    "num_cols_train_to_normalize=(num_cols_train_to_normalize-num_cols_train_to_normalize.mean())/num_cols_train_to_normalize.std()\n",
    "num_cols_test_to_normalize=(num_cols_test_to_normalize-num_cols_test_to_normalize.mean())/num_cols_test_to_normalize.std()\n",
    "\n",
    "\n",
    "#Merge Binary and numeric normalized\n",
    "num_cols_train=pd.concat([pd.DataFrame(num_cols_train),\n",
    "                               pd.DataFrame(num_cols_train_to_normalize)], axis=1)\n",
    "num_cols_test=pd.concat([pd.DataFrame(num_cols_test),\n",
    "                               pd.DataFrame(num_cols_test_to_normalize)], axis=1)\n",
    "\n",
    "print(mail_type_train.shape,mail_type_test.shape)\n",
    "print(tld_train.shape,tld_test.shape)\n",
    "print(org_train.shape,org_test.shape)\n",
    "print(num_cols_train.shape,num_cols_test.shape)\n",
    "print(num_cols_train.shape,num_cols_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25066, 3) (10745, 3)\n",
      "(25066, 9) (10745, 9)\n"
     ]
    }
   ],
   "source": [
    "#Encode Categorical\n",
    "\n",
    "\n",
    "#Deleted Dayweek,(soir nuit matin aprem),month, Doesnt help improve the score\n",
    "\n",
    "#More details about Date In the lastest cells\n",
    "import category_encoders as ce\n",
    "#,pd.DataFrame(td_train),pd.DataFrame(tm_train),pd.DataFrame(tday_train)\n",
    "#,pd.DataFrame(td_test),pd.DataFrame(tm_test),pd.DataFrame(tday_test)\n",
    "\n",
    "train_x= pd.concat([pd.DataFrame(mail_type_train),pd.DataFrame(org_train),pd.DataFrame(tld_train)], axis=1)\n",
    "test_x= pd.concat([pd.DataFrame(mail_type_test),pd.DataFrame(org_test),pd.DataFrame(tld_test)], axis=1)\n",
    "print(train_x.shape,test_x.shape)\n",
    "\n",
    "\n",
    "#train_x=train_x.fillna(\"Monday\")\n",
    "#test_x=test_x.fillna(\"Monday\")\n",
    "#################################### ENCODE train/test X ##############################\n",
    "\n",
    "## Do one hot encoding of categorical feature\n",
    "\n",
    "feat_enc = ce.CatBoostEncoder()\n",
    "\n",
    "feat_enc.fit(train_x,train_y['label'])\n",
    "train_x_featurized = pd.concat([pd.DataFrame(feat_enc.transform(train_x)),\n",
    "                                num_cols_train],axis=1,join=\"inner\")\n",
    "test_x_featurized = pd.concat([pd.DataFrame(feat_enc.transform(test_x)),\n",
    "                               num_cols_test],axis=1,join=\"inner\")\n",
    "\n",
    "#IF YOU ADD DATE\n",
    "#Normalization\n",
    "#train_x_featurized[\"tt\"]=(train_x_featurized[\"tt\"]-train_x_featurized[\"tt\"].mean())/train_x_featurized[\"tt\"].std()\n",
    "#test_x_featurized[\"tt\"]=(test_x_featurized[\"tt\"]-test_x_featurized[\"tt\"].mean())/test_x_featurized[\"tt\"].std()\n",
    "\n",
    "\n",
    "print(train_x_featurized.shape,test_x_featurized.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=test_x_featurized\n",
    "df_test.to_csv(r'df_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=train_x_featurized\n",
    "df_train[\"label\"]=train_y['label']\n",
    "#df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(r'df_train.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read csvs\n",
    "df_train = pd.read_csv('df_train.csv', index_col=0)\n",
    "df_test = pd.read_csv('df_test.csv', index_col=0)\n",
    "\n",
    "X_train=df_train.drop(columns=['label']).values\n",
    "y_train=df_train[\"label\"].values\n",
    "X_test=df_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohcine\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "y_train=enc.fit_transform(y_train.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.patches as patches\n",
    "import tensorflow as tf\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "import cv2\n",
    "from tensorflow.keras.optimizers import Adam,SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(256,activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(128,activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(64,activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(4,activation=\"softmax\")\n",
    "])\n",
    "\n",
    "#modelIET.compile(loss=\"categorical_crossentropy\",optimizer=\"rmsprop\")\n",
    "#opt=SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20052 samples, validate on 5014 samples\n",
      "Epoch 1/200\n",
      "20052/20052 [==============================] - 2s 83us/sample - loss: 0.8815 - accuracy: 0.6966 - val_loss: 0.5764 - val_accuracy: 0.7908\n",
      "Epoch 2/200\n",
      "20052/20052 [==============================] - 1s 32us/sample - loss: 0.5494 - accuracy: 0.8079 - val_loss: 0.4694 - val_accuracy: 0.8305\n",
      "Epoch 3/200\n",
      "20052/20052 [==============================] - 1s 33us/sample - loss: 0.4525 - accuracy: 0.8388 - val_loss: 0.4055 - val_accuracy: 0.8410\n",
      "Epoch 4/200\n",
      "20052/20052 [==============================] - 1s 40us/sample - loss: 0.4108 - accuracy: 0.8471 - val_loss: 0.3861 - val_accuracy: 0.8526\n",
      "Epoch 5/200\n",
      "20052/20052 [==============================] - 1s 31us/sample - loss: 0.3885 - accuracy: 0.8531 - val_loss: 0.3801 - val_accuracy: 0.8444\n",
      "Epoch 6/200\n",
      "20052/20052 [==============================] - 1s 30us/sample - loss: 0.3752 - accuracy: 0.8568 - val_loss: 0.3583 - val_accuracy: 0.8582\n",
      "Epoch 7/200\n",
      "20052/20052 [==============================] - 1s 44us/sample - loss: 0.3669 - accuracy: 0.8585 - val_loss: 0.3543 - val_accuracy: 0.8674\n",
      "Epoch 8/200\n",
      "20052/20052 [==============================] - 1s 49us/sample - loss: 0.3527 - accuracy: 0.8636 - val_loss: 0.3557 - val_accuracy: 0.8668\n",
      "Epoch 9/200\n",
      "20052/20052 [==============================] - 1s 46us/sample - loss: 0.3448 - accuracy: 0.8662 - val_loss: 0.3355 - val_accuracy: 0.8666\n",
      "Epoch 10/200\n",
      "20052/20052 [==============================] - 1s 43us/sample - loss: 0.3380 - accuracy: 0.8695 - val_loss: 0.3289 - val_accuracy: 0.8746\n",
      "Epoch 11/200\n",
      "20052/20052 [==============================] - 1s 45us/sample - loss: 0.3270 - accuracy: 0.8741 - val_loss: 0.3207 - val_accuracy: 0.8751\n",
      "Epoch 12/200\n",
      "20052/20052 [==============================] - 1s 46us/sample - loss: 0.3238 - accuracy: 0.8757 - val_loss: 0.3218 - val_accuracy: 0.8668\n",
      "Epoch 13/200\n",
      "20052/20052 [==============================] - 1s 44us/sample - loss: 0.3173 - accuracy: 0.8749 - val_loss: 0.3134 - val_accuracy: 0.8803loss: 0.3226 - accu\n",
      "Epoch 14/200\n",
      "20052/20052 [==============================] - 1s 40us/sample - loss: 0.3076 - accuracy: 0.8789 - val_loss: 0.3107 - val_accuracy: 0.8777\n",
      "Epoch 15/200\n",
      "20052/20052 [==============================] - 1s 45us/sample - loss: 0.3046 - accuracy: 0.8812 - val_loss: 0.3147 - val_accuracy: 0.8785\n",
      "Epoch 16/200\n",
      "20052/20052 [==============================] - 1s 44us/sample - loss: 0.3027 - accuracy: 0.8815 - val_loss: 0.3057 - val_accuracy: 0.8815\n",
      "Epoch 17/200\n",
      "20052/20052 [==============================] - 1s 44us/sample - loss: 0.2944 - accuracy: 0.8830 - val_loss: 0.3021 - val_accuracy: 0.8847\n",
      "Epoch 18/200\n",
      "20052/20052 [==============================] - 1s 45us/sample - loss: 0.2900 - accuracy: 0.8862 - val_loss: 0.2989 - val_accuracy: 0.8855\n",
      "Epoch 19/200\n",
      "20052/20052 [==============================] - 1s 40us/sample - loss: 0.2876 - accuracy: 0.8885 - val_loss: 0.2930 - val_accuracy: 0.8897\n",
      "Epoch 20/200\n",
      "20052/20052 [==============================] - 1s 36us/sample - loss: 0.2839 - accuracy: 0.8899 - val_loss: 0.2932 - val_accuracy: 0.8889\n",
      "Epoch 21/200\n",
      "20052/20052 [==============================] - 1s 39us/sample - loss: 0.2863 - accuracy: 0.8897 - val_loss: 0.2976 - val_accuracy: 0.8897\n",
      "Epoch 22/200\n",
      "20052/20052 [==============================] - 1s 34us/sample - loss: 0.2801 - accuracy: 0.8911 - val_loss: 0.2879 - val_accuracy: 0.8943\n",
      "Epoch 23/200\n",
      "20052/20052 [==============================] - 1s 40us/sample - loss: 0.2774 - accuracy: 0.8934 - val_loss: 0.2852 - val_accuracy: 0.8921\n",
      "Epoch 24/200\n",
      "20052/20052 [==============================] - 1s 38us/sample - loss: 0.2708 - accuracy: 0.8960 - val_loss: 0.2839 - val_accuracy: 0.8939\n",
      "Epoch 25/200\n",
      "20052/20052 [==============================] - 1s 39us/sample - loss: 0.2724 - accuracy: 0.8934 - val_loss: 0.2826 - val_accuracy: 0.8951\n",
      "Epoch 26/200\n",
      "20052/20052 [==============================] - 1s 35us/sample - loss: 0.2687 - accuracy: 0.8987 - val_loss: 0.2804 - val_accuracy: 0.8995\n",
      "Epoch 27/200\n",
      "20052/20052 [==============================] - 1s 43us/sample - loss: 0.2647 - accuracy: 0.8993 - val_loss: 0.2768 - val_accuracy: 0.8977\n",
      "Epoch 28/200\n",
      "20052/20052 [==============================] - 1s 37us/sample - loss: 0.2602 - accuracy: 0.9031 - val_loss: 0.2698 - val_accuracy: 0.9013\n",
      "Epoch 29/200\n",
      "20052/20052 [==============================] - 1s 38us/sample - loss: 0.2597 - accuracy: 0.8996 - val_loss: 0.2690 - val_accuracy: 0.9017\n",
      "Epoch 30/200\n",
      "20052/20052 [==============================] - 1s 37us/sample - loss: 0.2573 - accuracy: 0.9018 - val_loss: 0.2679 - val_accuracy: 0.8987\n",
      "Epoch 31/200\n",
      "20052/20052 [==============================] - 1s 36us/sample - loss: 0.2567 - accuracy: 0.9027 - val_loss: 0.2755 - val_accuracy: 0.8989\n",
      "Epoch 32/200\n",
      "20052/20052 [==============================] - 1s 37us/sample - loss: 0.2532 - accuracy: 0.9052 - val_loss: 0.2654 - val_accuracy: 0.9017\n",
      "Epoch 33/200\n",
      "20052/20052 [==============================] - 1s 35us/sample - loss: 0.2542 - accuracy: 0.9016 - val_loss: 0.2618 - val_accuracy: 0.9043\n",
      "Epoch 34/200\n",
      "20052/20052 [==============================] - 1s 36us/sample - loss: 0.2533 - accuracy: 0.9052 - val_loss: 0.2618 - val_accuracy: 0.9009\n",
      "Epoch 35/200\n",
      "20052/20052 [==============================] - 1s 39us/sample - loss: 0.2483 - accuracy: 0.9074 - val_loss: 0.2612 - val_accuracy: 0.9071\n",
      "Epoch 36/200\n",
      "20052/20052 [==============================] - 1s 36us/sample - loss: 0.2417 - accuracy: 0.9074 - val_loss: 0.2544 - val_accuracy: 0.9063\n",
      "Epoch 37/200\n",
      "20052/20052 [==============================] - 1s 34us/sample - loss: 0.2418 - accuracy: 0.9092 - val_loss: 0.2728 - val_accuracy: 0.9007\n",
      "Epoch 38/200\n",
      "20052/20052 [==============================] - 1s 36us/sample - loss: 0.2455 - accuracy: 0.9071 - val_loss: 0.2530 - val_accuracy: 0.9077\n",
      "Epoch 39/200\n",
      "20052/20052 [==============================] - ETA: 0s - loss: 0.2379 - accuracy: 0.90 - 1s 32us/sample - loss: 0.2380 - accuracy: 0.9095 - val_loss: 0.2488 - val_accuracy: 0.9093\n",
      "Epoch 40/200\n",
      "20052/20052 [==============================] - 1s 28us/sample - loss: 0.2377 - accuracy: 0.9091 - val_loss: 0.2543 - val_accuracy: 0.9053\n",
      "Epoch 41/200\n",
      "20052/20052 [==============================] - 1s 31us/sample - loss: 0.2396 - accuracy: 0.9086 - val_loss: 0.2570 - val_accuracy: 0.9085\n",
      "Epoch 42/200\n",
      "20052/20052 [==============================] - 1s 31us/sample - loss: 0.2354 - accuracy: 0.9092 - val_loss: 0.2563 - val_accuracy: 0.9049\n",
      "Epoch 43/200\n",
      "20052/20052 [==============================] - 1s 30us/sample - loss: 0.2330 - accuracy: 0.9128 - val_loss: 0.2426 - val_accuracy: 0.9118\n",
      "Epoch 44/200\n",
      "20052/20052 [==============================] - 1s 32us/sample - loss: 0.2305 - accuracy: 0.9131 - val_loss: 0.2841 - val_accuracy: 0.8935\n",
      "Epoch 45/200\n",
      "20052/20052 [==============================] - 1s 28us/sample - loss: 0.2363 - accuracy: 0.9090 - val_loss: 0.2568 - val_accuracy: 0.9065\n",
      "Epoch 46/200\n",
      "20052/20052 [==============================] - 1s 30us/sample - loss: 0.2268 - accuracy: 0.9124 - val_loss: 0.2518 - val_accuracy: 0.9089\n",
      "Epoch 47/200\n",
      "20052/20052 [==============================] - 1s 31us/sample - loss: 0.2287 - accuracy: 0.9123 - val_loss: 0.2402 - val_accuracy: 0.9126\n",
      "Epoch 48/200\n",
      "20052/20052 [==============================] - 1s 30us/sample - loss: 0.2272 - accuracy: 0.9127 - val_loss: 0.2409 - val_accuracy: 0.9124\n",
      "Epoch 49/200\n",
      "20052/20052 [==============================] - 1s 29us/sample - loss: 0.2238 - accuracy: 0.9158 - val_loss: 0.2386 - val_accuracy: 0.9126\n",
      "Epoch 50/200\n",
      "20052/20052 [==============================] - 1s 28us/sample - loss: 0.2222 - accuracy: 0.9143 - val_loss: 0.2360 - val_accuracy: 0.9118\n",
      "Epoch 51/200\n",
      "20052/20052 [==============================] - 1s 28us/sample - loss: 0.2217 - accuracy: 0.9152 - val_loss: 0.2426 - val_accuracy: 0.9134\n",
      "Epoch 52/200\n",
      "20052/20052 [==============================] - 1s 28us/sample - loss: 0.2205 - accuracy: 0.9155 - val_loss: 0.2386 - val_accuracy: 0.9138\n",
      "Epoch 53/200\n",
      "20052/20052 [==============================] - 1s 28us/sample - loss: 0.2225 - accuracy: 0.9133 - val_loss: 0.2435 - val_accuracy: 0.9081\n",
      "Epoch 54/200\n",
      "20052/20052 [==============================] - 1s 27us/sample - loss: 0.2180 - accuracy: 0.9162 - val_loss: 0.2351 - val_accuracy: 0.9124\n",
      "Epoch 55/200\n",
      "20052/20052 [==============================] - 1s 28us/sample - loss: 0.2212 - accuracy: 0.9147 - val_loss: 0.2335 - val_accuracy: 0.9156\n",
      "Epoch 56/200\n",
      "20052/20052 [==============================] - 1s 26us/sample - loss: 0.2231 - accuracy: 0.9173 - val_loss: 0.2328 - val_accuracy: 0.9166\n",
      "Epoch 57/200\n",
      "20052/20052 [==============================] - 1s 27us/sample - loss: 0.2183 - accuracy: 0.9179 - val_loss: 0.2311 - val_accuracy: 0.9144\n",
      "Epoch 58/200\n",
      "20052/20052 [==============================] - 1s 27us/sample - loss: 0.2176 - accuracy: 0.9163 - val_loss: 0.2353 - val_accuracy: 0.9132\n",
      "Epoch 59/200\n",
      "20052/20052 [==============================] - 1s 27us/sample - loss: 0.2142 - accuracy: 0.9190 - val_loss: 0.2299 - val_accuracy: 0.9132\n",
      "Epoch 60/200\n",
      "20052/20052 [==============================] - 1s 28us/sample - loss: 0.2136 - accuracy: 0.9191 - val_loss: 0.2338 - val_accuracy: 0.9148\n",
      "Epoch 61/200\n",
      "20052/20052 [==============================] - 1s 27us/sample - loss: 0.2146 - accuracy: 0.9186 - val_loss: 0.2425 - val_accuracy: 0.9099\n",
      "Epoch 62/200\n",
      "20052/20052 [==============================] - 1s 38us/sample - loss: 0.2150 - accuracy: 0.9191 - val_loss: 0.2372 - val_accuracy: 0.9162\n",
      "Epoch 63/200\n",
      "20052/20052 [==============================] - 1s 38us/sample - loss: 0.2139 - accuracy: 0.9185 - val_loss: 0.2290 - val_accuracy: 0.9158\n",
      "Epoch 64/200\n",
      "20052/20052 [==============================] - 1s 51us/sample - loss: 0.2080 - accuracy: 0.9202 - val_loss: 0.2388 - val_accuracy: 0.9114\n",
      "Epoch 65/200\n",
      "20052/20052 [==============================] - 1s 42us/sample - loss: 0.2137 - accuracy: 0.9189 - val_loss: 0.2298 - val_accuracy: 0.9120\n",
      "Epoch 66/200\n",
      "20052/20052 [==============================] - ETA: 0s - loss: 0.2106 - accuracy: 0.91 - 1s 32us/sample - loss: 0.2108 - accuracy: 0.9187 - val_loss: 0.2350 - val_accuracy: 0.9140\n",
      "Epoch 67/200\n",
      "20052/20052 [==============================] - 1s 33us/sample - loss: 0.2082 - accuracy: 0.9205 - val_loss: 0.2253 - val_accuracy: 0.9168\n",
      "Epoch 68/200\n",
      "20052/20052 [==============================] - 1s 41us/sample - loss: 0.2089 - accuracy: 0.9205 - val_loss: 0.2239 - val_accuracy: 0.9158\n",
      "Epoch 69/200\n",
      "20052/20052 [==============================] - 1s 39us/sample - loss: 0.2082 - accuracy: 0.9198 - val_loss: 0.2315 - val_accuracy: 0.9134\n",
      "Epoch 70/200\n",
      "20052/20052 [==============================] - 1s 41us/sample - loss: 0.2072 - accuracy: 0.9209 - val_loss: 0.2225 - val_accuracy: 0.9162 accuracy: 0.\n",
      "Epoch 71/200\n",
      "20052/20052 [==============================] - 1s 37us/sample - loss: 0.2021 - accuracy: 0.9240 - val_loss: 0.2334 - val_accuracy: 0.9146\n",
      "Epoch 72/200\n",
      "20052/20052 [==============================] - 1s 39us/sample - loss: 0.2041 - accuracy: 0.9221 - val_loss: 0.2239 - val_accuracy: 0.9170\n",
      "Epoch 73/200\n",
      "20052/20052 [==============================] - 1s 37us/sample - loss: 0.2028 - accuracy: 0.9222 - val_loss: 0.2238 - val_accuracy: 0.9126\n",
      "Epoch 74/200\n",
      "20052/20052 [==============================] - 1s 39us/sample - loss: 0.1986 - accuracy: 0.9251 - val_loss: 0.2252 - val_accuracy: 0.9172\n",
      "Epoch 75/200\n",
      "20052/20052 [==============================] - 1s 36us/sample - loss: 0.2008 - accuracy: 0.9238 - val_loss: 0.2223 - val_accuracy: 0.9168\n",
      "Epoch 76/200\n",
      "20052/20052 [==============================] - 1s 36us/sample - loss: 0.2051 - accuracy: 0.9204 - val_loss: 0.2333 - val_accuracy: 0.9130\n",
      "Epoch 77/200\n",
      "20052/20052 [==============================] - 1s 38us/sample - loss: 0.2149 - accuracy: 0.9191 - val_loss: 0.2281 - val_accuracy: 0.9150\n",
      "Epoch 78/200\n",
      "20052/20052 [==============================] - 1s 37us/sample - loss: 0.2053 - accuracy: 0.9235 - val_loss: 0.2269 - val_accuracy: 0.9154\n",
      "Epoch 79/200\n",
      "20052/20052 [==============================] - 1s 45us/sample - loss: 0.2045 - accuracy: 0.9229 - val_loss: 0.2272 - val_accuracy: 0.9178\n",
      "Epoch 80/200\n",
      "20052/20052 [==============================] - 1s 47us/sample - loss: 0.1959 - accuracy: 0.9256 - val_loss: 0.2245 - val_accuracy: 0.9162\n",
      "Epoch 81/200\n",
      "20052/20052 [==============================] - 1s 39us/sample - loss: 0.1964 - accuracy: 0.9253 - val_loss: 0.2271 - val_accuracy: 0.9184\n",
      "Epoch 82/200\n",
      "20052/20052 [==============================] - 1s 42us/sample - loss: 0.1973 - accuracy: 0.9244 - val_loss: 0.2187 - val_accuracy: 0.9152\n",
      "Epoch 83/200\n",
      "20052/20052 [==============================] - 1s 38us/sample - loss: 0.1953 - accuracy: 0.9262 - val_loss: 0.2305 - val_accuracy: 0.9156\n",
      "Epoch 84/200\n",
      "20052/20052 [==============================] - 1s 39us/sample - loss: 0.1977 - accuracy: 0.9236 - val_loss: 0.2287 - val_accuracy: 0.9160\n",
      "Epoch 85/200\n",
      "20052/20052 [==============================] - 1s 42us/sample - loss: 0.1964 - accuracy: 0.9241 - val_loss: 0.2230 - val_accuracy: 0.9170\n",
      "Epoch 86/200\n",
      "20052/20052 [==============================] - 1s 35us/sample - loss: 0.1930 - accuracy: 0.9254 - val_loss: 0.2261 - val_accuracy: 0.9166\n",
      "Epoch 87/200\n",
      "20052/20052 [==============================] - 1s 66us/sample - loss: 0.1921 - accuracy: 0.9267 - val_loss: 0.2231 - val_accuracy: 0.9144\n",
      "Epoch 88/200\n",
      "20052/20052 [==============================] - 1s 48us/sample - loss: 0.1889 - accuracy: 0.9260 - val_loss: 0.2217 - val_accuracy: 0.9172\n",
      "Epoch 89/200\n",
      "20052/20052 [==============================] - 1s 52us/sample - loss: 0.1923 - accuracy: 0.9264 - val_loss: 0.2231 - val_accuracy: 0.9180s - loss: 0.1891 - ac\n",
      "Epoch 90/200\n",
      "20052/20052 [==============================] - 1s 45us/sample - loss: 0.1907 - accuracy: 0.9268 - val_loss: 0.2311 - val_accuracy: 0.9144\n",
      "Epoch 91/200\n",
      "20052/20052 [==============================] - 1s 41us/sample - loss: 0.1930 - accuracy: 0.9265 - val_loss: 0.2240 - val_accuracy: 0.9156\n",
      "Epoch 92/200\n",
      "20052/20052 [==============================] - 1s 46us/sample - loss: 0.1942 - accuracy: 0.9234 - val_loss: 0.2422 - val_accuracy: 0.9132\n",
      "Epoch 93/200\n",
      "20052/20052 [==============================] - 1s 53us/sample - loss: 0.1947 - accuracy: 0.9241 - val_loss: 0.2217 - val_accuracy: 0.9150\n",
      "Epoch 94/200\n",
      "20052/20052 [==============================] - 1s 52us/sample - loss: 0.1875 - accuracy: 0.9278 - val_loss: 0.2166 - val_accuracy: 0.9196\n",
      "Epoch 95/200\n",
      "20052/20052 [==============================] - 1s 36us/sample - loss: 0.1875 - accuracy: 0.9275 - val_loss: 0.2127 - val_accuracy: 0.9200\n",
      "Epoch 96/200\n",
      "20052/20052 [==============================] - 1s 50us/sample - loss: 0.1856 - accuracy: 0.9291 - val_loss: 0.2191 - val_accuracy: 0.9176\n",
      "Epoch 97/200\n",
      "20052/20052 [==============================] - 1s 51us/sample - loss: 0.1871 - accuracy: 0.9273 - val_loss: 0.2199 - val_accuracy: 0.9208\n",
      "Epoch 98/200\n",
      "20052/20052 [==============================] - 1s 44us/sample - loss: 0.1862 - accuracy: 0.9283 - val_loss: 0.2247 - val_accuracy: 0.9170\n",
      "Epoch 99/200\n",
      "20052/20052 [==============================] - 1s 36us/sample - loss: 0.1850 - accuracy: 0.9287 - val_loss: 0.2210 - val_accuracy: 0.9210\n",
      "Epoch 100/200\n",
      "20052/20052 [==============================] - 1s 42us/sample - loss: 0.1873 - accuracy: 0.9280 - val_loss: 0.2272 - val_accuracy: 0.9192\n",
      "Epoch 101/200\n",
      "20052/20052 [==============================] - 1s 41us/sample - loss: 0.1884 - accuracy: 0.9269 - val_loss: 0.2198 - val_accuracy: 0.9200\n",
      "Epoch 102/200\n",
      "20052/20052 [==============================] - 1s 42us/sample - loss: 0.1846 - accuracy: 0.9279 - val_loss: 0.2173 - val_accuracy: 0.9200\n",
      "Epoch 103/200\n",
      "20052/20052 [==============================] - 1s 43us/sample - loss: 0.1870 - accuracy: 0.9264 - val_loss: 0.2211 - val_accuracy: 0.9182\n",
      "Epoch 104/200\n",
      "20052/20052 [==============================] - 1s 45us/sample - loss: 0.1829 - accuracy: 0.9281 - val_loss: 0.2335 - val_accuracy: 0.9130\n",
      "Epoch 105/200\n",
      "20052/20052 [==============================] - 1s 36us/sample - loss: 0.1880 - accuracy: 0.9285 - val_loss: 0.2184 - val_accuracy: 0.9200\n",
      "Epoch 106/200\n",
      "20052/20052 [==============================] - 1s 36us/sample - loss: 0.1873 - accuracy: 0.9296 - val_loss: 0.2212 - val_accuracy: 0.9186\n",
      "Epoch 107/200\n",
      "20052/20052 [==============================] - 1s 37us/sample - loss: 0.1798 - accuracy: 0.9304 - val_loss: 0.2295 - val_accuracy: 0.9202\n",
      "Epoch 108/200\n",
      "20052/20052 [==============================] - 1s 35us/sample - loss: 0.1820 - accuracy: 0.9279 - val_loss: 0.2184 - val_accuracy: 0.9232\n",
      "Epoch 109/200\n",
      "20052/20052 [==============================] - 1s 33us/sample - loss: 0.1812 - accuracy: 0.9294 - val_loss: 0.2347 - val_accuracy: 0.9160\n",
      "Epoch 110/200\n",
      "20052/20052 [==============================] - 1s 37us/sample - loss: 0.1837 - accuracy: 0.9289 - val_loss: 0.2137 - val_accuracy: 0.9230\n",
      "Epoch 111/200\n",
      "20052/20052 [==============================] - 1s 43us/sample - loss: 0.1795 - accuracy: 0.9298 - val_loss: 0.2179 - val_accuracy: 0.9184\n",
      "Epoch 112/200\n",
      "20052/20052 [==============================] - 1s 42us/sample - loss: 0.1806 - accuracy: 0.9296 - val_loss: 0.2168 - val_accuracy: 0.9172\n",
      "Epoch 113/200\n",
      "20052/20052 [==============================] - 1s 27us/sample - loss: 0.1769 - accuracy: 0.9310 - val_loss: 0.2174 - val_accuracy: 0.9216\n",
      "Epoch 114/200\n",
      "20052/20052 [==============================] - 1s 28us/sample - loss: 0.1773 - accuracy: 0.9307 - val_loss: 0.2260 - val_accuracy: 0.9210\n",
      "Epoch 115/200\n",
      "20052/20052 [==============================] - 1s 31us/sample - loss: 0.1827 - accuracy: 0.9278 - val_loss: 0.2132 - val_accuracy: 0.9198\n",
      "Epoch 116/200\n",
      "20052/20052 [==============================] - 1s 46us/sample - loss: 0.1752 - accuracy: 0.9326 - val_loss: 0.2171 - val_accuracy: 0.9240\n",
      "Epoch 117/200\n",
      "20052/20052 [==============================] - 1s 42us/sample - loss: 0.1739 - accuracy: 0.9325 - val_loss: 0.2113 - val_accuracy: 0.9222\n",
      "Epoch 118/200\n",
      "20052/20052 [==============================] - 1s 33us/sample - loss: 0.1735 - accuracy: 0.9319 - val_loss: 0.2274 - val_accuracy: 0.9164\n",
      "Epoch 119/200\n",
      "20052/20052 [==============================] - 1s 43us/sample - loss: 0.1777 - accuracy: 0.9317 - val_loss: 0.2160 - val_accuracy: 0.9226\n",
      "Epoch 120/200\n",
      "20052/20052 [==============================] - 1s 56us/sample - loss: 0.1755 - accuracy: 0.9318 - val_loss: 0.2116 - val_accuracy: 0.9212\n",
      "Epoch 121/200\n",
      "20052/20052 [==============================] - 1s 31us/sample - loss: 0.1751 - accuracy: 0.9320 - val_loss: 0.2139 - val_accuracy: 0.9220\n",
      "Epoch 122/200\n",
      "20052/20052 [==============================] - 1s 34us/sample - loss: 0.1733 - accuracy: 0.9341 - val_loss: 0.2130 - val_accuracy: 0.9180\n",
      "Epoch 123/200\n",
      "20052/20052 [==============================] - 1s 31us/sample - loss: 0.1699 - accuracy: 0.9344 - val_loss: 0.2160 - val_accuracy: 0.9218\n",
      "Epoch 124/200\n",
      "20052/20052 [==============================] - 1s 35us/sample - loss: 0.1741 - accuracy: 0.9322 - val_loss: 0.2213 - val_accuracy: 0.9206\n",
      "Epoch 125/200\n",
      "20052/20052 [==============================] - 1s 35us/sample - loss: 0.1707 - accuracy: 0.9334 - val_loss: 0.2123 - val_accuracy: 0.9230\n",
      "Epoch 126/200\n",
      "20052/20052 [==============================] - 1s 36us/sample - loss: 0.1721 - accuracy: 0.9324 - val_loss: 0.2140 - val_accuracy: 0.9194\n",
      "Epoch 127/200\n",
      "20052/20052 [==============================] - 1s 30us/sample - loss: 0.1717 - accuracy: 0.9346 - val_loss: 0.2205 - val_accuracy: 0.9214\n",
      "Epoch 128/200\n",
      "20052/20052 [==============================] - 1s 33us/sample - loss: 0.1747 - accuracy: 0.9325 - val_loss: 0.2164 - val_accuracy: 0.9234\n",
      "Epoch 129/200\n",
      "20052/20052 [==============================] - 1s 29us/sample - loss: 0.1704 - accuracy: 0.9336 - val_loss: 0.2129 - val_accuracy: 0.9228\n",
      "Epoch 130/200\n",
      "20052/20052 [==============================] - 1s 28us/sample - loss: 0.1709 - accuracy: 0.9337 - val_loss: 0.2206 - val_accuracy: 0.9226\n",
      "Epoch 131/200\n",
      "20052/20052 [==============================] - 1s 28us/sample - loss: 0.1705 - accuracy: 0.9341 - val_loss: 0.2098 - val_accuracy: 0.9226\n",
      "Epoch 132/200\n",
      "20052/20052 [==============================] - 1s 27us/sample - loss: 0.1687 - accuracy: 0.9343 - val_loss: 0.2136 - val_accuracy: 0.9204\n",
      "Epoch 133/200\n",
      "20052/20052 [==============================] - 1s 37us/sample - loss: 0.1694 - accuracy: 0.9327 - val_loss: 0.2114 - val_accuracy: 0.9188\n",
      "Epoch 134/200\n",
      "20052/20052 [==============================] - 1s 31us/sample - loss: 0.1670 - accuracy: 0.9343 - val_loss: 0.2113 - val_accuracy: 0.9226\n",
      "Epoch 135/200\n",
      "20052/20052 [==============================] - 1s 29us/sample - loss: 0.1641 - accuracy: 0.9348 - val_loss: 0.2209 - val_accuracy: 0.9174\n",
      "Epoch 136/200\n",
      "20052/20052 [==============================] - 0s 24us/sample - loss: 0.1720 - accuracy: 0.9329 - val_loss: 0.2136 - val_accuracy: 0.9258\n",
      "Epoch 137/200\n",
      "20052/20052 [==============================] - 0s 23us/sample - loss: 0.1680 - accuracy: 0.9348 - val_loss: 0.2078 - val_accuracy: 0.9206\n",
      "Epoch 138/200\n",
      "20052/20052 [==============================] - 0s 23us/sample - loss: 0.1674 - accuracy: 0.9357 - val_loss: 0.2155 - val_accuracy: 0.9234\n",
      "Epoch 139/200\n",
      "20052/20052 [==============================] - 1s 38us/sample - loss: 0.1650 - accuracy: 0.9350 - val_loss: 0.2186 - val_accuracy: 0.9218\n",
      "Epoch 140/200\n",
      "20052/20052 [==============================] - 1s 29us/sample - loss: 0.1670 - accuracy: 0.9360 - val_loss: 0.2164 - val_accuracy: 0.9186\n",
      "Epoch 141/200\n",
      "20052/20052 [==============================] - 1s 37us/sample - loss: 0.1638 - accuracy: 0.9357 - val_loss: 0.2149 - val_accuracy: 0.9234\n",
      "Epoch 142/200\n",
      "20052/20052 [==============================] - 1s 29us/sample - loss: 0.1649 - accuracy: 0.9365 - val_loss: 0.2079 - val_accuracy: 0.9272\n",
      "Epoch 143/200\n",
      "20052/20052 [==============================] - 1s 31us/sample - loss: 0.1654 - accuracy: 0.9346 - val_loss: 0.2274 - val_accuracy: 0.9158\n",
      "Epoch 144/200\n",
      "20052/20052 [==============================] - 1s 27us/sample - loss: 0.1681 - accuracy: 0.9339 - val_loss: 0.2132 - val_accuracy: 0.9250\n",
      "Epoch 145/200\n",
      "20052/20052 [==============================] - 1s 34us/sample - loss: 0.1639 - accuracy: 0.9361 - val_loss: 0.2206 - val_accuracy: 0.9216\n",
      "Epoch 146/200\n",
      "20052/20052 [==============================] - 1s 32us/sample - loss: 0.1634 - accuracy: 0.9371 - val_loss: 0.2200 - val_accuracy: 0.9202\n",
      "Epoch 147/200\n",
      "20052/20052 [==============================] - 1s 31us/sample - loss: 0.1644 - accuracy: 0.9358 - val_loss: 0.2154 - val_accuracy: 0.9226\n",
      "Epoch 148/200\n",
      "20052/20052 [==============================] - 1s 25us/sample - loss: 0.1624 - accuracy: 0.9376 - val_loss: 0.2102 - val_accuracy: 0.9252\n",
      "Epoch 149/200\n",
      "20052/20052 [==============================] - 1s 38us/sample - loss: 0.1765 - accuracy: 0.9333 - val_loss: 0.2134 - val_accuracy: 0.9214\n",
      "Epoch 150/200\n",
      "20052/20052 [==============================] - 1s 26us/sample - loss: 0.1616 - accuracy: 0.9369 - val_loss: 0.2227 - val_accuracy: 0.9194\n",
      "Epoch 151/200\n",
      "20052/20052 [==============================] - 0s 24us/sample - loss: 0.1614 - accuracy: 0.9365 - val_loss: 0.2137 - val_accuracy: 0.9242\n",
      "Epoch 152/200\n",
      "20052/20052 [==============================] - 1s 31us/sample - loss: 0.1583 - accuracy: 0.9378 - val_loss: 0.2104 - val_accuracy: 0.9244\n",
      "Epoch 153/200\n",
      "20052/20052 [==============================] - 1s 34us/sample - loss: 0.1599 - accuracy: 0.9375 - val_loss: 0.2124 - val_accuracy: 0.9250\n",
      "Epoch 154/200\n",
      "20052/20052 [==============================] - 1s 27us/sample - loss: 0.1601 - accuracy: 0.9377 - val_loss: 0.2111 - val_accuracy: 0.9242\n",
      "Epoch 155/200\n",
      "20052/20052 [==============================] - 0s 24us/sample - loss: 0.1599 - accuracy: 0.9367 - val_loss: 0.2218 - val_accuracy: 0.9202\n",
      "Epoch 156/200\n",
      "20052/20052 [==============================] - 1s 29us/sample - loss: 0.1602 - accuracy: 0.9371 - val_loss: 0.2191 - val_accuracy: 0.9208\n",
      "Epoch 157/200\n",
      "20052/20052 [==============================] - 1s 27us/sample - loss: 0.1575 - accuracy: 0.9378 - val_loss: 0.2185 - val_accuracy: 0.9232\n",
      "Epoch 158/200\n",
      "20052/20052 [==============================] - 0s 23us/sample - loss: 0.1586 - accuracy: 0.9379 - val_loss: 0.2189 - val_accuracy: 0.9234\n",
      "Epoch 159/200\n",
      "20052/20052 [==============================] - 0s 24us/sample - loss: 0.1584 - accuracy: 0.9386 - val_loss: 0.2278 - val_accuracy: 0.9194\n",
      "Epoch 160/200\n",
      "20052/20052 [==============================] - 1s 25us/sample - loss: 0.1610 - accuracy: 0.9383 - val_loss: 0.2102 - val_accuracy: 0.9260\n",
      "Epoch 161/200\n",
      "20052/20052 [==============================] - 0s 24us/sample - loss: 0.1590 - accuracy: 0.9381 - val_loss: 0.2129 - val_accuracy: 0.9232\n",
      "Epoch 162/200\n",
      "20052/20052 [==============================] - 0s 24us/sample - loss: 0.1546 - accuracy: 0.9404 - val_loss: 0.2229 - val_accuracy: 0.9236\n",
      "Epoch 163/200\n",
      "20052/20052 [==============================] - 0s 23us/sample - loss: 0.1569 - accuracy: 0.9396 - val_loss: 0.2127 - val_accuracy: 0.9236\n",
      "Epoch 164/200\n",
      "20052/20052 [==============================] - 0s 23us/sample - loss: 0.1585 - accuracy: 0.9373 - val_loss: 0.2299 - val_accuracy: 0.9192\n",
      "Epoch 165/200\n",
      "20052/20052 [==============================] - 1s 25us/sample - loss: 0.1564 - accuracy: 0.9386 - val_loss: 0.2224 - val_accuracy: 0.9222\n",
      "Epoch 166/200\n",
      "20052/20052 [==============================] - 1s 33us/sample - loss: 0.1567 - accuracy: 0.9387 - val_loss: 0.2131 - val_accuracy: 0.9252\n",
      "Epoch 167/200\n",
      "20052/20052 [==============================] - 1s 27us/sample - loss: 0.1593 - accuracy: 0.9383 - val_loss: 0.2147 - val_accuracy: 0.9286\n",
      "Epoch 168/200\n",
      "20052/20052 [==============================] - 1s 26us/sample - loss: 0.1574 - accuracy: 0.9374 - val_loss: 0.2172 - val_accuracy: 0.9272\n",
      "Epoch 169/200\n",
      "20052/20052 [==============================] - 0s 22us/sample - loss: 0.1558 - accuracy: 0.9398 - val_loss: 0.2150 - val_accuracy: 0.9276\n",
      "Epoch 170/200\n",
      "20052/20052 [==============================] - 0s 23us/sample - loss: 0.1543 - accuracy: 0.9384 - val_loss: 0.2162 - val_accuracy: 0.9242\n",
      "Epoch 171/200\n",
      "20052/20052 [==============================] - 0s 25us/sample - loss: 0.1503 - accuracy: 0.9414 - val_loss: 0.2152 - val_accuracy: 0.9244\n",
      "Epoch 172/200\n",
      "20052/20052 [==============================] - 0s 24us/sample - loss: 0.1510 - accuracy: 0.9423 - val_loss: 0.2110 - val_accuracy: 0.9262\n",
      "Epoch 173/200\n",
      "20052/20052 [==============================] - 0s 23us/sample - loss: 0.1536 - accuracy: 0.9414 - val_loss: 0.2193 - val_accuracy: 0.9228\n",
      "Epoch 174/200\n",
      "20052/20052 [==============================] - 0s 24us/sample - loss: 0.1538 - accuracy: 0.9395 - val_loss: 0.2258 - val_accuracy: 0.9236\n",
      "Epoch 175/200\n",
      "20052/20052 [==============================] - 0s 24us/sample - loss: 0.1512 - accuracy: 0.9409 - val_loss: 0.2129 - val_accuracy: 0.9270\n",
      "Epoch 176/200\n",
      "20052/20052 [==============================] - 0s 25us/sample - loss: 0.1513 - accuracy: 0.9413 - val_loss: 0.2144 - val_accuracy: 0.9234\n",
      "Epoch 177/200\n",
      "20052/20052 [==============================] - 0s 25us/sample - loss: 0.1546 - accuracy: 0.9402 - val_loss: 0.2201 - val_accuracy: 0.9210\n",
      "Epoch 178/200\n",
      "20052/20052 [==============================] - 0s 25us/sample - loss: 0.1514 - accuracy: 0.9415 - val_loss: 0.2196 - val_accuracy: 0.9240\n",
      "Epoch 179/200\n",
      "20052/20052 [==============================] - 0s 25us/sample - loss: 0.1555 - accuracy: 0.9387 - val_loss: 0.2238 - val_accuracy: 0.9192\n",
      "Epoch 180/200\n",
      "20052/20052 [==============================] - 0s 23us/sample - loss: 0.1573 - accuracy: 0.9385 - val_loss: 0.2127 - val_accuracy: 0.9276\n",
      "Epoch 181/200\n",
      "20052/20052 [==============================] - 0s 23us/sample - loss: 0.1515 - accuracy: 0.9395 - val_loss: 0.2134 - val_accuracy: 0.9244\n",
      "Epoch 182/200\n",
      "20052/20052 [==============================] - 0s 24us/sample - loss: 0.1485 - accuracy: 0.9419 - val_loss: 0.2155 - val_accuracy: 0.9280\n",
      "Epoch 183/200\n",
      "20052/20052 [==============================] - 0s 24us/sample - loss: 0.1481 - accuracy: 0.9412 - val_loss: 0.2218 - val_accuracy: 0.9222\n",
      "Epoch 184/200\n",
      "20052/20052 [==============================] - 0s 24us/sample - loss: 0.1596 - accuracy: 0.9393 - val_loss: 0.2184 - val_accuracy: 0.9260\n",
      "Epoch 185/200\n",
      "20052/20052 [==============================] - 0s 24us/sample - loss: 0.1534 - accuracy: 0.9392 - val_loss: 0.2144 - val_accuracy: 0.9216\n",
      "Epoch 186/200\n",
      "20052/20052 [==============================] - 0s 23us/sample - loss: 0.1530 - accuracy: 0.9408 - val_loss: 0.2134 - val_accuracy: 0.9220\n",
      "Epoch 187/200\n",
      "20052/20052 [==============================] - 0s 24us/sample - loss: 0.1464 - accuracy: 0.9413 - val_loss: 0.2149 - val_accuracy: 0.9248\n",
      "Epoch 188/200\n",
      "20052/20052 [==============================] - 1s 25us/sample - loss: 0.1518 - accuracy: 0.9408 - val_loss: 0.2175 - val_accuracy: 0.9244\n",
      "Epoch 189/200\n",
      "20052/20052 [==============================] - 0s 24us/sample - loss: 0.1524 - accuracy: 0.9408 - val_loss: 0.2168 - val_accuracy: 0.9246\n",
      "Epoch 190/200\n",
      "20052/20052 [==============================] - 0s 22us/sample - loss: 0.1488 - accuracy: 0.9409 - val_loss: 0.2174 - val_accuracy: 0.9248\n",
      "Epoch 191/200\n",
      "20052/20052 [==============================] - 0s 25us/sample - loss: 0.1478 - accuracy: 0.9411 - val_loss: 0.2145 - val_accuracy: 0.9250\n",
      "Epoch 192/200\n",
      "20052/20052 [==============================] - 0s 24us/sample - loss: 0.1454 - accuracy: 0.9425 - val_loss: 0.2277 - val_accuracy: 0.9246\n",
      "Epoch 193/200\n",
      "20052/20052 [==============================] - 0s 24us/sample - loss: 0.1543 - accuracy: 0.9396 - val_loss: 0.2195 - val_accuracy: 0.9244\n",
      "Epoch 194/200\n",
      "20052/20052 [==============================] - 0s 25us/sample - loss: 0.1503 - accuracy: 0.9413 - val_loss: 0.2233 - val_accuracy: 0.9260\n",
      "Epoch 195/200\n",
      "20052/20052 [==============================] - 0s 23us/sample - loss: 0.1469 - accuracy: 0.9425 - val_loss: 0.2195 - val_accuracy: 0.9268\n",
      "Epoch 196/200\n",
      "20052/20052 [==============================] - 0s 24us/sample - loss: 0.1451 - accuracy: 0.9424 - val_loss: 0.2221 - val_accuracy: 0.9262\n",
      "Epoch 197/200\n",
      "20052/20052 [==============================] - 0s 24us/sample - loss: 0.1424 - accuracy: 0.9442 - val_loss: 0.2151 - val_accuracy: 0.9264\n",
      "Epoch 198/200\n",
      "20052/20052 [==============================] - 0s 25us/sample - loss: 0.1432 - accuracy: 0.9435 - val_loss: 0.2225 - val_accuracy: 0.9228\n",
      "Epoch 199/200\n",
      "20052/20052 [==============================] - 0s 23us/sample - loss: 0.1448 - accuracy: 0.9434 - val_loss: 0.2198 - val_accuracy: 0.9278\n",
      "Epoch 200/200\n",
      "20052/20052 [==============================] - 1s 26us/sample - loss: 0.1451 - accuracy: 0.9426 - val_loss: 0.2248 - val_accuracy: 0.9264\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=200,batch_size=512,validation_split=0.2,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy of our model is 0.9203134\n",
      "The validation accuracy of our model is 0.91213995\n"
     ]
    }
   ],
   "source": [
    "train_acc=np.mean(history.history['accuracy'])\n",
    "val_acc=np.mean(history.history['val_accuracy'])\n",
    "print(\"The training accuracy of our model is \"+ str(train_acc))\n",
    "print(\"The validation accuracy of our model is \"+ str(val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the metrics\n",
    "fig = plt.figure()\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_acc', 'val_acc'], loc='lower left')\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss', 'val_loss'], loc='upper left')\n",
    "#plt.ylim([0, 1.5])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'modelIET' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-334528e75fe8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodelIET\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0menc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'modelIET' is not defined"
     ]
    }
   ],
   "source": [
    "y_test = modelIET.predict(X_test)\n",
    "y=enc.inverse_transform(y_test)\n",
    "y=np.array(pd.DataFrame(y)[0]).astype(int)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IM SAVING\n"
     ]
    }
   ],
   "source": [
    "print(\"IM SAVING\")\n",
    "## Save results to submission file\n",
    "pred_df = pd.DataFrame(y, columns=['label'])\n",
    "pred_df.to_csv(\"submission.csv\", index=True, index_label='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10740</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10741</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10742</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10743</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10744</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10745 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label\n",
       "0        2.0\n",
       "1        0.0\n",
       "2        0.0\n",
       "3        3.0\n",
       "4        0.0\n",
       "...      ...\n",
       "10740    0.0\n",
       "10741    0.0\n",
       "10742    3.0\n",
       "10743    0.0\n",
       "10744    0.0\n",
       "\n",
       "[10745 rows x 1 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
